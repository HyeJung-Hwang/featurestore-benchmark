{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_columns = [\n",
    "    \"FINANCIAL SERVICES\", \"SHOES\", \"PERSONAL CARE\", \"PAINT AND ACCESSORIES\", \"DSD GROCERY\", \"MEAT - FRESH & FROZEN\",\n",
    "    \"DAIRY\", \"PETS AND SUPPLIES\", \"HOUSEHOLD CHEMICALS/SUPP\", \"IMPULSE MERCHANDISE\", \"PRODUCE\",\n",
    "    \"CANDY, TOBACCO, COOKIES\", \"GROCERY DRY GOODS\", \"BOYS WEAR\", \"FABRICS AND CRAFTS\", \"JEWELRY AND SUNGLASSES\",\n",
    "    \"MENS WEAR\", \"ACCESSORIES\", \"HOME MANAGEMENT\", \"FROZEN FOODS\", \"SERVICE DELI\", \"INFANT CONSUMABLE HARDLINES\",\n",
    "    \"PRE PACKED DELI\", \"COOK AND DINE\", \"PHARMACY OTC\", \"LADIESWEAR\", \"COMM BREAD\", \"BAKERY\", \"HOUSEHOLD PAPER GOODS\",\n",
    "    \"CELEBRATION\", \"HARDWARE\", \"BEAUTY\", \"AUTOMOTIVE\", \"BOOKS AND MAGAZINES\", \"SEAFOOD\", \"OFFICE SUPPLIES\",\n",
    "    \"LAWN AND GARDEN\", \"SHEER HOSIERY\", \"WIRELESS\", \"BEDDING\", \"BATH AND SHOWER\", \"HORTICULTURE AND ACCESS\",\n",
    "    \"HOME DECOR\", \"TOYS\", \"INFANT APPAREL\", \"LADIES SOCKS\", \"PLUS AND MATERNITY\", \"ELECTRONICS\",\n",
    "    \"GIRLS WEAR, 4-6X  AND 7-14\", \"BRAS & SHAPEWEAR\", \"LIQUOR,WINE,BEER\", \"SLEEPWEAR/FOUNDATIONS\",\n",
    "    \"CAMERAS AND SUPPLIES\", \"SPORTING GOODS\", \"PLAYERS AND ELECTRONICS\", \"PHARMACY RX\", \"MENSWEAR\", \"OPTICAL - FRAMES\",\n",
    "    \"SWIMWEAR/OUTERWEAR\", \"OTHER DEPARTMENTS\", \"MEDIA AND GAMING\", \"FURNITURE\", \"OPTICAL - LENSES\", \"SEASONAL\",\n",
    "    \"LARGE HOUSEHOLD GOODS\", \"1-HR PHOTO\", \"CONCEPT STORES\", \"HEALTH AND BEAUTY AIDS\"\n",
    "]\n",
    "weekday_columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "featureColumns = ['scan_count', 'scan_count_abs'] + weekday_columns + department_columns\n",
    "\n",
    "label_column = 'trip_type'\n",
    "\n",
    "# deleted label 14, since only 4 samples existed in the sample data set\n",
    "label_range = [3, 4, 5, 6, 7, 8, 9, 12, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
    "               37, 38, 39, 40, 41, 42, 43, 44, 999]\n",
    "sorted_labels = sorted(label_range, key=str)\n",
    "label_to_index = {k: v for v, k in enumerate(sorted_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "order_path = r\"/home/hjhwang/workspace/tpcx-ai-v1.0.3.1/output/data/training/order.csv\"\n",
    "lineitem_path = r\"/home/hjhwang/workspace/tpcx-ai-v1.0.3.1/output/data/training/lineitem.csv\"\n",
    "product_path = r\"/home/hjhwang/workspace/tpcx-ai-v1.0.3.1/output/data/training/product.csv\"\n",
    "\n",
    "\n",
    "# Output Path\n",
    "work_dir = r\"/home/hjhwang/workspace/tpcx-ai-v1.0.3.1/output/model/uc08\"\n",
    "output = work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(order_path: str, lineitem_path: str, product_path: str) -> pd.DataFrame:\n",
    "    order_data = pd.read_csv(order_path, parse_dates=['date'])\n",
    "    lineitem_data = pd.read_csv(lineitem_path)\n",
    "    product_data = pd.read_csv(product_path)\n",
    "    data = order_data.merge(lineitem_data, left_on='o_order_id', right_on='li_order_id')\n",
    "    data = data.merge(product_data, left_on='li_product_id', right_on='p_product_id')\n",
    "\n",
    "    if 'trip_type' in data.columns:\n",
    "        return data[['o_order_id', 'date', 'department', 'quantity', 'trip_type']]\n",
    "    else:\n",
    "        return data[['o_order_id', 'date', 'department', 'quantity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load time:\t 8.572427896782756\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "raw_data = load_data(order_path, lineitem_path, product_path)\n",
    "end = timeit.default_timer()\n",
    "load_time = end - start\n",
    "print('load time:\\t', load_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv(\"raw_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   o_order_id       date    department  quantity  trip_type\n",
      "0           1 2010-07-14  SERVICE DELI         2          8\n",
      "1          15 2011-11-19  SERVICE DELI         2          8\n",
      "2          15 2011-11-19  SERVICE DELI         1          8\n",
      "3          15 2011-11-19  SERVICE DELI         2          8\n",
      "4          36 2011-10-12  SERVICE DELI         3          8\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition - Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    return label_to_index[label]\n",
    "\n",
    "def pre_process(raw_data: pd.DataFrame) -> (np.array, pd.DataFrame):\n",
    "    # check if this data needs labeling(has trip type label)\n",
    "    has_labels = label_column in raw_data.columns\n",
    "\n",
    "    def scan_count(x):\n",
    "        return np.sum(x)\n",
    "\n",
    "    def scan_count_abs(x):\n",
    "        return np.sum(np.abs(x))\n",
    "\n",
    "    def weekday(x):\n",
    "        return np.min(x)\n",
    "\n",
    "    def trip_type(x):\n",
    "        return np.min(x)\n",
    "\n",
    "    if has_labels:\n",
    "        agg_func = {\n",
    "            'scan_count': [scan_count, scan_count_abs],\n",
    "            'weekday': weekday,\n",
    "            'trip_type': trip_type\n",
    "        }\n",
    "    else:\n",
    "        agg_func = {\n",
    "            'scan_count': [scan_count, scan_count_abs],\n",
    "            'weekday': weekday\n",
    "        }\n",
    "\n",
    "    raw_data['scan_count'] = raw_data['quantity']\n",
    "    raw_data['weekday'] = raw_data['date'].dt.day_name()\n",
    "    features_scan_count: pd.DataFrame = raw_data.groupby(['o_order_id']).agg(agg_func)\n",
    "\n",
    "    features_scan_count.columns = features_scan_count.columns.droplevel(0)\n",
    "\n",
    "    def grper(x):\n",
    "        return int(pd.Series.count(x) > 0)\n",
    "\n",
    "    weekdays = raw_data.pivot_table(index='o_order_id', columns='weekday', values='scan_count',\n",
    "                                    aggfunc=grper).fillna(0.0)\n",
    "\n",
    "    missing_weekdays = set(weekday_columns) - set(weekdays.columns)\n",
    "    for c in missing_weekdays:\n",
    "        weekdays.insert(1, c, 0.0)\n",
    "\n",
    "    departments = raw_data.pivot_table(index='o_order_id', columns='department', values='scan_count',\n",
    "                                       aggfunc='sum')\n",
    "\n",
    "    missing_cols = set(department_columns) - set(departments.columns)\n",
    "    for c in missing_cols:\n",
    "        departments.insert(1, c, 0.0)\n",
    "\n",
    "    final_data: pd.DataFrame = features_scan_count.drop(columns=['weekday']) \\\n",
    "        .join(weekdays) \\\n",
    "        .join(departments) \\\n",
    "        .fillna(0.0)\n",
    "\n",
    "    if label_column in final_data.columns:\n",
    "        # remove tiny classes\n",
    "        final_data = final_data[final_data['trip_type'] != 14]\n",
    "        final_data[label_column] = final_data['trip_type'].apply(encode_label)\n",
    "        return final_data[label_column].values.ravel(), final_data[featureColumns]\n",
    "    else:\n",
    "        return None, final_data[featureColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-process time:\t 697.7915676683187\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "(labels, data) = pre_process(raw_data)\n",
    "end = timeit.default_timer()\n",
    "pre_process_time = end - start\n",
    "print('pre-process time:\\t', pre_process_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\".data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data: pd.DataFrame, labels, num_rounds):\n",
    "    xgboost_clf = XGBClassifier(tree_method='hist', objective='multi:softprob', n_estimators=num_rounds)\n",
    "\n",
    "    features = csr_matrix(training_data[featureColumns])\n",
    "    model = xgboost_clf.fit(features, labels)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time:\t 2433.700179751031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/hjhwang/workspace/tpcx-ai-v1.0.3.1/output/model/uc08/uc08.python.model.run-u08-on-nb']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "num_rounds = 100\n",
    "model_file_name =  'uc08.python.model'\n",
    "model = train(data, labels, num_rounds)\n",
    "end = timeit.default_timer()\n",
    "train_time = end - start\n",
    "print('train time:\\t', train_time)\n",
    "\n",
    "model_file_name = 'uc08.python.model.run-u08-on-nb'\n",
    "joblib.dump(model, work_dir + '/' + model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label(label):\n",
    "    return sorted_labels[label]\n",
    "\n",
    "def serve(model, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    sparse_data = csr_matrix(data)\n",
    "    predictions = model.predict(sparse_data)\n",
    "    dec_fun = np.vectorize(decode_label)\n",
    "    predictions_df = pd.DataFrame({'o_order_id': data.index, 'trip_type': dec_fun(predictions)})\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serve time:\t 78.48762742616236\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(work_dir + '/' + model_file_name)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "predictions = serve(model, data)\n",
    "end = timeit.default_timer()\n",
    "serve_time = end - start\n",
    "\n",
    "predictions['o_order_id'] = data.index\n",
    "predictions.to_csv(output + f'/{model_file_name}_predictions.csv', index=False)\n",
    "\n",
    "print('serve time:\\t', serve_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
